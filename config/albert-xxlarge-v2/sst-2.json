{
    "pretrained_weight":  "distilbert-base-uncased",
    "dataset": "generic",
    "generic_data_dir": "data/SST-2",
    "pattern": "[TEXT1] it is [LBL]",
    "pattern_idx": 1,
    "dict_verbalizer": {"0": "No", "1": "Yes"},
    "idx_txt_trim": 1,
    "max_text_length": 64,
    "batch_size": 16,
    "eval_batch_size": 8,
    "num_batches": 1000,
    "max_num_lbl_tok": 1,
    "eval_every": 50,
    "warmup_ratio": 0.06,
    "mask_alpha": 0.105,
    "grad_accumulation_factor": 1,
    "seed": 42,
    "lr": 1e-5,
    "weight_decay": 1e-2
}
